Move things from this list to done.txt or wontdo.txt, for later review of what I have and have not done, to help with creating documentation and synthesizing other ideas for features/design.

CURRENT TASK AT HAND (finish or abort cleanly before starting something else!):
- current subtask: show analyses for a wordform, e.g. `dry analyze Baseline "eka"` will list them like it would during parsing
-- should I allow this to be shortened to `dry form "eka"`? maybe but will need config about which row is the form, so maybe omit this for now
- other subtasks:
-- break out of parsing loop when user wants to do this; upon being shown possible analyses of a form, user can do something like `:reassign 2>3`, `:reassign 1,2>3`, etc.
-- allow simultaneous reassigning of multiple analyses to one target, e.g. `1,2>3` will reassign 1 to 3 and 2 to 3


TODO:
- get notes out of FLEx! will use flexpy for this and then merge them into the relevant .dry files
- have a line be able to refer to another line in the same or another text, e.g. ref: Kaikai 260, and have the program edit the text files so that the references are all symmetric
- approving an analysis throughout a text or the whole corpus
- replacing a partial-word parse/gloss with a new one (e.g. change all -ko-mu 'fut-3sg' to -komu '3sg.fut')
- search/grep for things, highlight them in colors in the terminal output
- change which rows are being edited during parsing
- re-parse a line from scratch
- re-ask to parse anything with the unknown marker for its analysis (default: parsed as "?", glossed as "?")
- search lexicon
- add lexical items that aren't in any text (might be best to just have a lexicon .dry file for this)
- change which heuristic is used for guessing word analysis: most recently seen in text, most commonly seen in text, most commonly seen overall
- make config subcommand that can do the following things:
-- change working directory for FLEx files
-- change which rows are shown for parsing/reading a text
- be able to type diacritics and symbols either directly or using IPA keyboard shortcuts like @3 and DryBones will interpret as meaning acute accent, can have stuff like this configurable as well, can have preset configs for SIL IPA keyboard and LaTeX, and the rest the user can change/define
-- ReplaceAccents.py in the Hurukui repo currently does this, but should move it into a DryBones command
- browse analyses by wordform
- add project-level and global-level shorthands, e.g. for Hurukui I want to type DS to mean (pa|mana|ne|pua|pia|puna|pina) when searching
- join lines
- split lines
- import and export drybones-format text file, start with plain text that is just copied to the texts/ dir for a project, users could in theory edit the text files in there directly much as they could edit git objects, but this is inadvisable, better to do text export, edit it, then text import
-- later, can import and export texts as other formats e.g. flextext, even something like .tsv or .csv for editing or getting stats in a spreadsheet
- tags for lines for things like grammar phenomena, e.g. #focus, suggest similar known tags (or even completion as you type) or prompt to make a new one
- notation with question marks for not-yet-done stuff, a single cell in a row is one: '?', the whole row (or maybe the rest of the row before/after a known cell) is two: '??'
- notation for items that should be left out of alignment, like tfs, maybe wrap in angle brackets '<>' for a cell that is to be ignored but it's there so the alignment doesn't get messed up (as we will enforce all rows in a line have either only 1 or N cells)
- allow question mark at end of a cell's value to indicate uncertainty, e.g. glossing a weird use of "ona" as 'bone?' because it usually means "bone" but that makes less sense here, or glossing "minde" as 'together?' because that word's meaning is overall uncertain to the analyst but 'together' is their best guess right now
- period "." between words in a single gloss-phrase, e.g. "go.down", but colon ":" between gloss-parts that are fused (up to analyst to do this, but useful if you have fusion between gloss-parts and one or more of those is more than one word, e.g. "opa-" 'give.to:1sg.rec')
- might be a good idea to have row labels explicitly marked with a symbol meaning alignment? it can be configured, but for clarity to user it would be nice to remind them that certain lines like the raw baseline are not aligned (only 1 cell) and others are even though they may look very similar to non-aligned rows
- functionality for extracting rows containing extra stuff that user put into the .dry file, splitting it out into a separate file like a .csv where the lines with that info get rows in the spreadsheet and others either get blank rows or are excluded depending on user choice, so then I can use the DryBones text format for annotating LVC examples but then split that info out of the main .dry file so it doesn't litter it with too much stuff, can also have functionality for re-importing info like that into the main .dry file
- detect when a word form is unacceptable, or when a gloss of a given word form is unacceptable even if the word is sometimes acceptable, by looking at the judgment fields found with that form/gloss, e.g. Hurukui "akai" can be validly glossed as "follow-ser" but not as "follow-2sg.imp", while "akaya" is just not a valid form at all (see e.g. [4.198.0-1])
- have sub-parses/glosses for complex forms, e.g. "hamunge pite" meaning 'God' can be its own cell, but the corpus should also know that this is actually composed of "hamunge" 'man' and "pite" 'big' rather than just homophones or something
- find single cell forms with "_" or whatever char is used for a within-cell space, so that user can make sure they have sub-parses/glosses for their parts (e.g. "opopo_kunie_apono" 'car' should be sub-analyzed as "opopo kuni-e apono" 'thing leg-3sg.poss three')
- random exploration mode, walk through utterances in the corpus in random order, want features that let the user find stuff that needs to be re-parsed/analyzed as well as to notice new patterns
- command to check for bad chars/tokens in baselines, e.g. "*", "~", "[", "]", so that user can go clean up lines that fell through the cracks during importing
- play audio clip! it would be amazing if, given a file for the text and timestamps for the line, you could type `dry play Kom 59` and hear it!
-- texts should also be allowed to overwrite the text-global filename on certain lines, since who knows if someone will mix together audio files in one .dry text
- text-level metadata in a line in the text's .dry file (or, another option, in a separate config file in the same dir, need to decide which is better, I like it all being in one place so I like it as part of the text's .dry file so we don't have to worry about linking different files together for this)
- get copy-paste-ready string for an example to include in a document, e.g. `dry example WP1 23` will print the line WP1 23 as baseline/parse/gloss/translation, with line designation and/or timestamp in parentheses after the translation, with tabs between cells; which lines are printed and other things about this can be configuration settings
- retire line designations forever within a project, will be useful once I relabel examples somehow, so each line can keep a list of its old designations, and any new line designation will be checked against these to ensure we don't accidentally start using an old designation for a new line (so that cross references that need to be relabeled in my written work won't start pointing to the wrong line)
- consolidate REPLs into the same basic code if it makes sense to do so; existing REPLs: `dry parse {fp}`, `dry search` (implementation in progress)
- reorder the rows, and/or enforce a certain row order, on a text file, e.g. `dry reorder N,Baseline,Gloss,Translation`, should warn if it omits any existing lines (don't let it delete omitted ones, just put them sorted at the end or something), should show user the existing line labels beforehand, can also make it do some default order based on order of first appearance in the file
- concordance view of something you searched for
- corpus stats (how many words, how many texts)
- during loading lines from a .dry file, make it clearer to user why rows are misaligned (different numbers of cells): show which cells are aligned with which so they can more easily spot the problems and fix the .dry file (example: PAIA_flexpy_export.drytest, line 9)
- duplicate line into a,b,c (however many the user wants)
- automate removing spaces around punctuation that FLEx put in there, for easier importing for myself and others who migrate from FLEx to DryBones
-- more generally for the importing workflow, use the commits of the Hurukui repo where the message is about "importing/imported" some texts in summer 2025, can use these as snapshots of what someone's data might look like after exporting via flexpy, also reference the file "hurukui/DryBones/FlextextToDrybonesWorkflow.txt" which describes the workflow I used during this time and which should be made easier on users
-- the dream would be a drybones command to import a whole .fwdata directly, can call flexpy functions as part of this
- don't repeat the searching action on ";;" in `dry search` REPL, just show the results again that you already computed (user should be made aware that in the same running REPL, the corpus will NOT be reloaded from disk; if they want to load new changes, they'll need to exit it and run `dry search` again, or also I can put a command in there to load any new changes and continue the REPL, whereupon invocations of ";;" will actually re-run the search)

command name/syntax ideas:
- dry publish {text}  # copies the text's file to a specified directory where more permanent versions live (like what I want to do with {Hurukui repo}/Texts/ as of 2025-04-22), can have option for overwrite existing file or however I want to handle that
- dry show-unparsed-lines
- dry show-status-all
- dry search Bl "omore" --ignore-diacritics  # let's ignore case and diacritics by default (maybe configurable), pass -c for case sensitive and -d for diacritic sensitive
- dry search Bl "\bkhai"  # use regex always or have a flag for it? let's use -r/--raw for raw string, regex by default
-- each of the options case sens/insens, diacritic sens/insens, regex/raw should have its own flag, and if the flag matches the current config default then tell user that it's already doing this by default, and what they can do to switch the config setting
- dry search Gl "fire"
- dry search Fr "^Don't" --ignore-case
-- maybe instead of having subcommands for word/gloss/translation, I should have field names? since I want this to be pretty extensible for other fields the user might add, like who knows maybe they want a field for speaker name for every line in every text, so should be able to regex search all of those too given the label that the user has put on those lines
- dry wc Kaikai  # word count, line count
- dry text-info Kaikai  # some info about the text, such as word count, line count, title, whatever else?
- dry morpheme show-all  # show all morphemes
- dry morpheme search  # search for a morpheme
- dry wrap {string}  # print out the input string with the line delimiters around it
